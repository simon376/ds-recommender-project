{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Processing for GoodReads Dataset\n",
    "## Pre-processing input data, creating Embeddings, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pprint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = './data/cleaned/'\n",
    "fn_books = 'goodreads_books_mystery_thriller_crime.pkl'\n",
    "fn_reviews = 'goodreads_reviews_mystery_thriller_crime.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_pickle(os.path.join(DIR, fn_reviews))\n",
    "df_books = pd.read_pickle(os.path.join(DIR, fn_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5e212a62bced17b4dbe41150e5bb9037</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>6392944</td>\n",
       "      <td>3</td>\n",
       "      <td>I haven't read a fun mystery book in a while a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ede853b14dc4583f96cf5d120af636f</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>28684704</td>\n",
       "      <td>3</td>\n",
       "      <td>A fun, fast paced science fiction thriller. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e4d61801907e591018bdc3442a9cf2b</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>32283133</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.telegraph.co.uk/culture/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>022bb6daffa49adc27f6b20b6ebeb37d</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>17860739</td>\n",
       "      <td>4</td>\n",
       "      <td>An amazing and unique creation: JJ Abrams and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0e317947e1fd341f573192111bb2921d</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>8694005</td>\n",
       "      <td>3</td>\n",
       "      <td>The Name of the Rose is a thrilling Dan Brown-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           user_id   book_id  \\\n",
       "review_id                                                                      \n",
       "5e212a62bced17b4dbe41150e5bb9037  8842281e1d1347389f2ab93d60773d4d   6392944   \n",
       "2ede853b14dc4583f96cf5d120af636f  8842281e1d1347389f2ab93d60773d4d  28684704   \n",
       "8e4d61801907e591018bdc3442a9cf2b  8842281e1d1347389f2ab93d60773d4d  32283133   \n",
       "022bb6daffa49adc27f6b20b6ebeb37d  8842281e1d1347389f2ab93d60773d4d  17860739   \n",
       "0e317947e1fd341f573192111bb2921d  8842281e1d1347389f2ab93d60773d4d   8694005   \n",
       "\n",
       "                                  rating  \\\n",
       "review_id                                  \n",
       "5e212a62bced17b4dbe41150e5bb9037       3   \n",
       "2ede853b14dc4583f96cf5d120af636f       3   \n",
       "8e4d61801907e591018bdc3442a9cf2b       0   \n",
       "022bb6daffa49adc27f6b20b6ebeb37d       4   \n",
       "0e317947e1fd341f573192111bb2921d       3   \n",
       "\n",
       "                                                                        review_text  \n",
       "review_id                                                                            \n",
       "5e212a62bced17b4dbe41150e5bb9037  I haven't read a fun mystery book in a while a...  \n",
       "2ede853b14dc4583f96cf5d120af636f  A fun, fast paced science fiction thriller. I ...  \n",
       "8e4d61801907e591018bdc3442a9cf2b           http://www.telegraph.co.uk/culture/10...  \n",
       "022bb6daffa49adc27f6b20b6ebeb37d  An amazing and unique creation: JJ Abrams and ...  \n",
       "0e317947e1fd341f573192111bb2921d  The Name of the Rose is a thrilling Dan Brown-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id        object\n",
       "book_id        uint32\n",
       "rating          uint8\n",
       "review_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>description</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6066814</th>\n",
       "      <td>b'Crowner Royal (Crowner John Mystery, #13)'</td>\n",
       "      <td>15</td>\n",
       "      <td>[{'count': '159', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>3.93</td>\n",
       "      <td>London, 1196. At the command of Richard the Li...</td>\n",
       "      <td>37778</td>\n",
       "      <td>Bernard Knight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33394837</th>\n",
       "      <td>b\"The House of Memory (Pluto's Snitch #2)\"</td>\n",
       "      <td>60</td>\n",
       "      <td>[{'count': '54', 'name': 'currently-reading'},...</td>\n",
       "      <td>4.33</td>\n",
       "      <td></td>\n",
       "      <td>242185</td>\n",
       "      <td>Carolyn Haines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29074697</th>\n",
       "      <td>b'The Slaughtered Virgin of Zenopolis (Inspect...</td>\n",
       "      <td>23</td>\n",
       "      <td>[{'count': '90', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>3.49</td>\n",
       "      <td>BATHS, BANKS AND ROMAN INSURRECTION Detective ...</td>\n",
       "      <td>15104629</td>\n",
       "      <td>David  Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902202</th>\n",
       "      <td>b'Dead in the Morning (Patrick Grant, #1)'</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'count': '51', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Gerald breezily introduced his wife, Helen, to...</td>\n",
       "      <td>190988</td>\n",
       "      <td>Margaret Yorke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9671977</th>\n",
       "      <td>b'Aristotele e i misteri di Eleusi'</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'count': '48', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>3.54</td>\n",
       "      <td>\"I misteri di Eleusi\" e il quinto romanzo di A...</td>\n",
       "      <td>337108</td>\n",
       "      <td>Margaret Doody</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "book_id                                                       \n",
       "6066814        b'Crowner Royal (Crowner John Mystery, #13)'   \n",
       "33394837         b\"The House of Memory (Pluto's Snitch #2)\"   \n",
       "29074697  b'The Slaughtered Virgin of Zenopolis (Inspect...   \n",
       "1902202          b'Dead in the Morning (Patrick Grant, #1)'   \n",
       "9671977                 b'Aristotele e i misteri di Eleusi'   \n",
       "\n",
       "          text_reviews_count  \\\n",
       "book_id                        \n",
       "6066814                   15   \n",
       "33394837                  60   \n",
       "29074697                  23   \n",
       "1902202                    8   \n",
       "9671977                    3   \n",
       "\n",
       "                                            popular_shelves  average_rating  \\\n",
       "book_id                                                                       \n",
       "6066814   [{'count': '159', 'name': 'to-read'}, {'count'...            3.93   \n",
       "33394837  [{'count': '54', 'name': 'currently-reading'},...            4.33   \n",
       "29074697  [{'count': '90', 'name': 'to-read'}, {'count':...            3.49   \n",
       "1902202   [{'count': '51', 'name': 'to-read'}, {'count':...            3.30   \n",
       "9671977   [{'count': '48', 'name': 'to-read'}, {'count':...            3.54   \n",
       "\n",
       "                                                description  author_id  \\\n",
       "book_id                                                                  \n",
       "6066814   London, 1196. At the command of Richard the Li...      37778   \n",
       "33394837                                                        242185   \n",
       "29074697  BATHS, BANKS AND ROMAN INSURRECTION Detective ...   15104629   \n",
       "1902202   Gerald breezily introduced his wife, Helen, to...     190988   \n",
       "9671977   \"I misteri di Eleusi\" e il quinto romanzo di A...     337108   \n",
       "\n",
       "             author_name  \n",
       "book_id                   \n",
       "6066814   Bernard Knight  \n",
       "33394837  Carolyn Haines  \n",
       "29074697    David  Blake  \n",
       "1902202   Margaret Yorke  \n",
       "9671977   Margaret Doody  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>title</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>description</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0e317947e1fd341f573192111bb2921d</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>8694005</td>\n",
       "      <td>3</td>\n",
       "      <td>The Name of the Rose is a thrilling Dan Brown-...</td>\n",
       "      <td>b'The Name of the Rose'</td>\n",
       "      <td>99</td>\n",
       "      <td>[{'count': '8209', 'name': 'to-read'}, {'count...</td>\n",
       "      <td>4.11</td>\n",
       "      <td>The year is 1327. Franciscans in a wealthy Ita...</td>\n",
       "      <td>1730</td>\n",
       "      <td>Umberto Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276918357312212384ac6415ceb9159</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>6652906</td>\n",
       "      <td>3</td>\n",
       "      <td>** spoiler alert **   Hooked me equally as wel...</td>\n",
       "      <td>b'The Girl Who Played with Fire (Millennium, #2)'</td>\n",
       "      <td>772</td>\n",
       "      <td>[{'count': '6613', 'name': 'fiction'}, {'count...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>Part blistering espionage thriller, part rivet...</td>\n",
       "      <td>706255</td>\n",
       "      <td>Stieg Larsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ee704921386f88893900829c037abd0</th>\n",
       "      <td>4fdf8e419e36ae2e82bc44376768e280</td>\n",
       "      <td>6652906</td>\n",
       "      <td>4</td>\n",
       "      <td>Don't start these books unless you're ready to...</td>\n",
       "      <td>b'The Girl Who Played with Fire (Millennium, #2)'</td>\n",
       "      <td>772</td>\n",
       "      <td>[{'count': '6613', 'name': 'fiction'}, {'count...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>Part blistering espionage thriller, part rivet...</td>\n",
       "      <td>706255</td>\n",
       "      <td>Stieg Larsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26e59823f1936fe9030d85262f1477e1</th>\n",
       "      <td>446728d221c1343b92e1e4ff5545a843</td>\n",
       "      <td>6652906</td>\n",
       "      <td>5</td>\n",
       "      <td>Loved it! Not as much as the first but it this...</td>\n",
       "      <td>b'The Girl Who Played with Fire (Millennium, #2)'</td>\n",
       "      <td>772</td>\n",
       "      <td>[{'count': '6613', 'name': 'fiction'}, {'count...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>Part blistering espionage thriller, part rivet...</td>\n",
       "      <td>706255</td>\n",
       "      <td>Stieg Larsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83370bd38023a2fd928b2b6114c2b210</th>\n",
       "      <td>fe0ad83a30bcd7fbe65ac1670b2b01e1</td>\n",
       "      <td>6652906</td>\n",
       "      <td>5</td>\n",
       "      <td>Once again Larsson does not disappoint. Althou...</td>\n",
       "      <td>b'The Girl Who Played with Fire (Millennium, #2)'</td>\n",
       "      <td>772</td>\n",
       "      <td>[{'count': '6613', 'name': 'fiction'}, {'count...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>Part blistering espionage thriller, part rivet...</td>\n",
       "      <td>706255</td>\n",
       "      <td>Stieg Larsson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           user_id  book_id  \\\n",
       "review_id                                                                     \n",
       "0e317947e1fd341f573192111bb2921d  8842281e1d1347389f2ab93d60773d4d  8694005   \n",
       "4276918357312212384ac6415ceb9159  8842281e1d1347389f2ab93d60773d4d  6652906   \n",
       "9ee704921386f88893900829c037abd0  4fdf8e419e36ae2e82bc44376768e280  6652906   \n",
       "26e59823f1936fe9030d85262f1477e1  446728d221c1343b92e1e4ff5545a843  6652906   \n",
       "83370bd38023a2fd928b2b6114c2b210  fe0ad83a30bcd7fbe65ac1670b2b01e1  6652906   \n",
       "\n",
       "                                  rating  \\\n",
       "review_id                                  \n",
       "0e317947e1fd341f573192111bb2921d       3   \n",
       "4276918357312212384ac6415ceb9159       3   \n",
       "9ee704921386f88893900829c037abd0       4   \n",
       "26e59823f1936fe9030d85262f1477e1       5   \n",
       "83370bd38023a2fd928b2b6114c2b210       5   \n",
       "\n",
       "                                                                        review_text  \\\n",
       "review_id                                                                             \n",
       "0e317947e1fd341f573192111bb2921d  The Name of the Rose is a thrilling Dan Brown-...   \n",
       "4276918357312212384ac6415ceb9159  ** spoiler alert **   Hooked me equally as wel...   \n",
       "9ee704921386f88893900829c037abd0  Don't start these books unless you're ready to...   \n",
       "26e59823f1936fe9030d85262f1477e1  Loved it! Not as much as the first but it this...   \n",
       "83370bd38023a2fd928b2b6114c2b210  Once again Larsson does not disappoint. Althou...   \n",
       "\n",
       "                                                                              title  \\\n",
       "review_id                                                                             \n",
       "0e317947e1fd341f573192111bb2921d                            b'The Name of the Rose'   \n",
       "4276918357312212384ac6415ceb9159  b'The Girl Who Played with Fire (Millennium, #2)'   \n",
       "9ee704921386f88893900829c037abd0  b'The Girl Who Played with Fire (Millennium, #2)'   \n",
       "26e59823f1936fe9030d85262f1477e1  b'The Girl Who Played with Fire (Millennium, #2)'   \n",
       "83370bd38023a2fd928b2b6114c2b210  b'The Girl Who Played with Fire (Millennium, #2)'   \n",
       "\n",
       "                                  text_reviews_count  \\\n",
       "review_id                                              \n",
       "0e317947e1fd341f573192111bb2921d                  99   \n",
       "4276918357312212384ac6415ceb9159                 772   \n",
       "9ee704921386f88893900829c037abd0                 772   \n",
       "26e59823f1936fe9030d85262f1477e1                 772   \n",
       "83370bd38023a2fd928b2b6114c2b210                 772   \n",
       "\n",
       "                                                                    popular_shelves  \\\n",
       "review_id                                                                             \n",
       "0e317947e1fd341f573192111bb2921d  [{'count': '8209', 'name': 'to-read'}, {'count...   \n",
       "4276918357312212384ac6415ceb9159  [{'count': '6613', 'name': 'fiction'}, {'count...   \n",
       "9ee704921386f88893900829c037abd0  [{'count': '6613', 'name': 'fiction'}, {'count...   \n",
       "26e59823f1936fe9030d85262f1477e1  [{'count': '6613', 'name': 'fiction'}, {'count...   \n",
       "83370bd38023a2fd928b2b6114c2b210  [{'count': '6613', 'name': 'fiction'}, {'count...   \n",
       "\n",
       "                                  average_rating  \\\n",
       "review_id                                          \n",
       "0e317947e1fd341f573192111bb2921d            4.11   \n",
       "4276918357312212384ac6415ceb9159            4.22   \n",
       "9ee704921386f88893900829c037abd0            4.22   \n",
       "26e59823f1936fe9030d85262f1477e1            4.22   \n",
       "83370bd38023a2fd928b2b6114c2b210            4.22   \n",
       "\n",
       "                                                                        description  \\\n",
       "review_id                                                                             \n",
       "0e317947e1fd341f573192111bb2921d  The year is 1327. Franciscans in a wealthy Ita...   \n",
       "4276918357312212384ac6415ceb9159  Part blistering espionage thriller, part rivet...   \n",
       "9ee704921386f88893900829c037abd0  Part blistering espionage thriller, part rivet...   \n",
       "26e59823f1936fe9030d85262f1477e1  Part blistering espionage thriller, part rivet...   \n",
       "83370bd38023a2fd928b2b6114c2b210  Part blistering espionage thriller, part rivet...   \n",
       "\n",
       "                                  author_id    author_name  \n",
       "review_id                                                   \n",
       "0e317947e1fd341f573192111bb2921d       1730    Umberto Eco  \n",
       "4276918357312212384ac6415ceb9159     706255  Stieg Larsson  \n",
       "9ee704921386f88893900829c037abd0     706255  Stieg Larsson  \n",
       "26e59823f1936fe9030d85262f1477e1     706255  Stieg Larsson  \n",
       "83370bd38023a2fd928b2b6114c2b210     706255  Stieg Larsson  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = pd.merge(df_reviews, df_books, left_on=\"book_id\", right_index=True)\n",
    "df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.272600e+04</td>\n",
       "      <td>22726.000000</td>\n",
       "      <td>22726.000000</td>\n",
       "      <td>22726.000000</td>\n",
       "      <td>2.272600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.249417e+07</td>\n",
       "      <td>3.702323</td>\n",
       "      <td>1417.564420</td>\n",
       "      <td>3.861244</td>\n",
       "      <td>2.209577e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.061642e+07</td>\n",
       "      <td>1.176469</td>\n",
       "      <td>3763.856472</td>\n",
       "      <td>0.282423</td>\n",
       "      <td>3.636851e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>1.300000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.002539e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1.706100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.183545e+07</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>1.471520e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.116935e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>879.000000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>3.413185e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.640284e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24868.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.732060e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book_id        rating  text_reviews_count  average_rating  \\\n",
       "count  2.272600e+04  22726.000000        22726.000000    22726.000000   \n",
       "mean   1.249417e+07      3.702323         1417.564420        3.861244   \n",
       "std    1.061642e+07      1.176469         3763.856472        0.282423   \n",
       "min    2.300000e+02      0.000000            1.000000        2.190000   \n",
       "25%    1.002539e+06      3.000000           34.000000        3.700000   \n",
       "50%    1.183545e+07      4.000000          184.000000        3.880000   \n",
       "75%    2.116935e+07      5.000000          879.000000        4.050000   \n",
       "max    3.640284e+07      5.000000        24868.000000        5.000000   \n",
       "\n",
       "          author_id  \n",
       "count  2.272600e+04  \n",
       "mean   2.209577e+06  \n",
       "std    3.636851e+06  \n",
       "min    1.300000e+02  \n",
       "25%    1.706100e+04  \n",
       "50%    1.471520e+05  \n",
       "75%    3.413185e+06  \n",
       "max    1.732060e+07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 6066814 to 23826\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   title               50000 non-null  object \n",
      " 1   text_reviews_count  50000 non-null  uint32 \n",
      " 2   popular_shelves     50000 non-null  object \n",
      " 3   average_rating      50000 non-null  float64\n",
      " 4   description         50000 non-null  object \n",
      " 5   author_id           50000 non-null  int64  \n",
      " 6   author_name         48081 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4), uint32(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Reviews and Book Infos\n",
    "#### only 4272 book-review pairs are overlapping in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>title</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>description</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3ba2d0f573bd246be03abe6d7e02fe5d</th>\n",
       "      <td>1e946b8f76d5a75414946767cd18cff9</td>\n",
       "      <td>6411961</td>\n",
       "      <td>3</td>\n",
       "      <td>Perfect reading for when you're home sick on a...</td>\n",
       "      <td>b'The Lost Symbol (Robert Langdon, #3)'</td>\n",
       "      <td>21569</td>\n",
       "      <td>[{'count': '9279', 'name': 'currently-reading'...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>WHAT IS LOST... WILL BE FOUND In this stunning...</td>\n",
       "      <td>630</td>\n",
       "      <td>Dan Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94a7379eb0cdd8ec55b2c943eb59a52b</th>\n",
       "      <td>9059ac97d0f44419021a6c092014e721</td>\n",
       "      <td>6411961</td>\n",
       "      <td>4</td>\n",
       "      <td>WHAT WORKS IN THE LOST SYMBOL   The entire fir...</td>\n",
       "      <td>b'The Lost Symbol (Robert Langdon, #3)'</td>\n",
       "      <td>21569</td>\n",
       "      <td>[{'count': '9279', 'name': 'currently-reading'...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>WHAT IS LOST... WILL BE FOUND In this stunning...</td>\n",
       "      <td>630</td>\n",
       "      <td>Dan Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a901824aeb09e8eff73ad165d7011082</th>\n",
       "      <td>248a173e53445b16a3fea5ef89df81fb</td>\n",
       "      <td>6411961</td>\n",
       "      <td>4</td>\n",
       "      <td>I guess I am a sucker for Dan Brown's books. I...</td>\n",
       "      <td>b'The Lost Symbol (Robert Langdon, #3)'</td>\n",
       "      <td>21569</td>\n",
       "      <td>[{'count': '9279', 'name': 'currently-reading'...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>WHAT IS LOST... WILL BE FOUND In this stunning...</td>\n",
       "      <td>630</td>\n",
       "      <td>Dan Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd451f680f846d20376c5a5ca9ef4eab</th>\n",
       "      <td>00ce07379fb4a962964dcfde4e146a84</td>\n",
       "      <td>6411961</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall, I really liked this book. I think Dan...</td>\n",
       "      <td>b'The Lost Symbol (Robert Langdon, #3)'</td>\n",
       "      <td>21569</td>\n",
       "      <td>[{'count': '9279', 'name': 'currently-reading'...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>WHAT IS LOST... WILL BE FOUND In this stunning...</td>\n",
       "      <td>630</td>\n",
       "      <td>Dan Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3f2384966f5c9951c0f914b1424e705</th>\n",
       "      <td>86b0f8caad0c89c9b9ee9c5061e7d3db</td>\n",
       "      <td>6411961</td>\n",
       "      <td>2</td>\n",
       "      <td>To be reviwed later.</td>\n",
       "      <td>b'The Lost Symbol (Robert Langdon, #3)'</td>\n",
       "      <td>21569</td>\n",
       "      <td>[{'count': '9279', 'name': 'currently-reading'...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>WHAT IS LOST... WILL BE FOUND In this stunning...</td>\n",
       "      <td>630</td>\n",
       "      <td>Dan Brown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           user_id  book_id  \\\n",
       "review_id                                                                     \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d  1e946b8f76d5a75414946767cd18cff9  6411961   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b  9059ac97d0f44419021a6c092014e721  6411961   \n",
       "a901824aeb09e8eff73ad165d7011082  248a173e53445b16a3fea5ef89df81fb  6411961   \n",
       "dd451f680f846d20376c5a5ca9ef4eab  00ce07379fb4a962964dcfde4e146a84  6411961   \n",
       "d3f2384966f5c9951c0f914b1424e705  86b0f8caad0c89c9b9ee9c5061e7d3db  6411961   \n",
       "\n",
       "                                  rating  \\\n",
       "review_id                                  \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d       3   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b       4   \n",
       "a901824aeb09e8eff73ad165d7011082       4   \n",
       "dd451f680f846d20376c5a5ca9ef4eab       4   \n",
       "d3f2384966f5c9951c0f914b1424e705       2   \n",
       "\n",
       "                                                                        review_text  \\\n",
       "review_id                                                                             \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d  Perfect reading for when you're home sick on a...   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b  WHAT WORKS IN THE LOST SYMBOL   The entire fir...   \n",
       "a901824aeb09e8eff73ad165d7011082  I guess I am a sucker for Dan Brown's books. I...   \n",
       "dd451f680f846d20376c5a5ca9ef4eab  Overall, I really liked this book. I think Dan...   \n",
       "d3f2384966f5c9951c0f914b1424e705                               To be reviwed later.   \n",
       "\n",
       "                                                                    title  \\\n",
       "review_id                                                                   \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d  b'The Lost Symbol (Robert Langdon, #3)'   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b  b'The Lost Symbol (Robert Langdon, #3)'   \n",
       "a901824aeb09e8eff73ad165d7011082  b'The Lost Symbol (Robert Langdon, #3)'   \n",
       "dd451f680f846d20376c5a5ca9ef4eab  b'The Lost Symbol (Robert Langdon, #3)'   \n",
       "d3f2384966f5c9951c0f914b1424e705  b'The Lost Symbol (Robert Langdon, #3)'   \n",
       "\n",
       "                                  text_reviews_count  \\\n",
       "review_id                                              \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d               21569   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b               21569   \n",
       "a901824aeb09e8eff73ad165d7011082               21569   \n",
       "dd451f680f846d20376c5a5ca9ef4eab               21569   \n",
       "d3f2384966f5c9951c0f914b1424e705               21569   \n",
       "\n",
       "                                                                    popular_shelves  \\\n",
       "review_id                                                                             \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d  [{'count': '9279', 'name': 'currently-reading'...   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b  [{'count': '9279', 'name': 'currently-reading'...   \n",
       "a901824aeb09e8eff73ad165d7011082  [{'count': '9279', 'name': 'currently-reading'...   \n",
       "dd451f680f846d20376c5a5ca9ef4eab  [{'count': '9279', 'name': 'currently-reading'...   \n",
       "d3f2384966f5c9951c0f914b1424e705  [{'count': '9279', 'name': 'currently-reading'...   \n",
       "\n",
       "                                  average_rating  \\\n",
       "review_id                                          \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d            3.66   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b            3.66   \n",
       "a901824aeb09e8eff73ad165d7011082            3.66   \n",
       "dd451f680f846d20376c5a5ca9ef4eab            3.66   \n",
       "d3f2384966f5c9951c0f914b1424e705            3.66   \n",
       "\n",
       "                                                                        description  \\\n",
       "review_id                                                                             \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d  WHAT IS LOST... WILL BE FOUND In this stunning...   \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b  WHAT IS LOST... WILL BE FOUND In this stunning...   \n",
       "a901824aeb09e8eff73ad165d7011082  WHAT IS LOST... WILL BE FOUND In this stunning...   \n",
       "dd451f680f846d20376c5a5ca9ef4eab  WHAT IS LOST... WILL BE FOUND In this stunning...   \n",
       "d3f2384966f5c9951c0f914b1424e705  WHAT IS LOST... WILL BE FOUND In this stunning...   \n",
       "\n",
       "                                  author_id author_name  \n",
       "review_id                                                \n",
       "3ba2d0f573bd246be03abe6d7e02fe5d        630   Dan Brown  \n",
       "94a7379eb0cdd8ec55b2c943eb59a52b        630   Dan Brown  \n",
       "a901824aeb09e8eff73ad165d7011082        630   Dan Brown  \n",
       "dd451f680f846d20376c5a5ca9ef4eab        630   Dan Brown  \n",
       "d3f2384966f5c9951c0f914b1424e705        630   Dan Brown  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22726 entries, 0e317947e1fd341f573192111bb2921d to 921812c9edc173c6d12e000723b9e667\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             22726 non-null  object \n",
      " 1   book_id             22726 non-null  uint32 \n",
      " 2   rating              22726 non-null  uint8  \n",
      " 3   review_text         22726 non-null  object \n",
      " 4   title               22726 non-null  object \n",
      " 5   text_reviews_count  22726 non-null  uint32 \n",
      " 6   popular_shelves     22726 non-null  object \n",
      " 7   average_rating      22726 non-null  float64\n",
      " 8   description         22726 non-null  object \n",
      " 9   author_id           22726 non-null  int64  \n",
      " 10  author_name         22279 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6), uint32(2), uint8(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews + Books joinen ? für Titel usw. ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_title_lookup = tf.keras.layers.StringLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'The Woman in White', 'The Adventures of Sherlock Holmes', 'Rebecca', 'The Hound of the Baskervilles']\n"
     ]
    }
   ],
   "source": [
    "book_title_lookup.adapt(df_books['title'])\n",
    "print(f\"Vocabulary: {book_title_lookup.get_vocabulary()[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can translate raw tokens (title) into embedding ids (here -> 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_title_lookup(\"The Woman in White\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you have OOV (out of vocabulary) for unknown tokens. StringLookup can use multiple OOV indices. the more indices, the less likely two different feature values will hash to the same OOV index. To take it to the next level, let's _just_ use hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up a large number of bins to reduce the chance of hash collisions.\n",
    "num_hashing_bins = 200_000\n",
    "\n",
    "book_title_hashing = tf.keras.layers.Hashing(\n",
    "    num_bins=num_hashing_bins\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([145026], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_title_hashing(['The Woman in White'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn those integers into **Embeddings**\n",
    "> An embedding layer has two dimensions: the first dimension tells us how many distinct categories we can embed; the second tells us how large the vector representing each of them can be. When creating the embedding layer for movie titles, we are going to set the first value to the size of our title vocabulary (or the number of hashing bins). The second is up to us: the larger it is, the higher the capacity of the model, but the slower it is to fit and serve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_title_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup. (for whatever reason..)\n",
    "    input_dim=book_title_lookup.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String -> Integer -> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_title_model = tf.keras.Sequential([tf.keras.Input(shape=(1,), dtype=tf.string), book_title_lookup, book_title_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01066036,  0.01711277,  0.04086823, -0.04574196,\n",
       "         -0.00500498,  0.02479979,  0.04201926,  0.0478866 ,\n",
       "         -0.00592098,  0.00510074, -0.02413275,  0.01563613,\n",
       "          0.04536356,  0.0133328 ,  0.01701099, -0.04780373,\n",
       "         -0.03997608,  0.00044893, -0.0154395 , -0.01296217,\n",
       "         -0.03021021,  0.02254916, -0.02640446,  0.04348096,\n",
       "          0.01255165,  0.03839214,  0.03369657,  0.00730436,\n",
       "          0.01088259,  0.00588713,  0.03960041, -0.04956684]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_title_model.predict(['The Woman in White'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt das gleiche mit User IDs \n",
    "--> nicht nötig, da sie schon pure ints sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Ratings\n",
    "not sure if necessary, but hey, doesn't hurt.\n",
    "not sure if min/max rescaling (0 - 1) or normalization is better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_scaling = tf.keras.layers.Rescaling(scale=1/5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized rating: [[1.0962977]], was 5\n",
      "normalized rating: [[1.0962977]], was 5\n",
      "normalized rating: [[0.25075173]], was 4\n",
      "normalized rating: [[-1.4403403]], was 2\n",
      "normalized rating: [[1.0962977]], was 5\n"
     ]
    }
   ],
   "source": [
    "rating_normalization = tf.keras.layers.Normalization()\n",
    "rating_normalization.adapt(df_reviews['rating'])\n",
    "for x in df_reviews['rating'].sample(5):\n",
    "    print(f\"normalized rating: {rating_normalization(x)}, was {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jetzt hab ich halt Kontinuerliche Werte aus Diskreten gemacht. das ist eigentlich dumm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_scaling(df_reviews['rating'].sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich bleib bei den rescaled Ratings. ist dann schön 0 - 1 aber auch nicht kategorisch, weil ja durchaus ein linearer Zusammenhang besteht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: nur englische Bücher verwenden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_text = tf.keras.layers.TextVectorization()\n",
    "description_text.adapt(df_books['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id\n",
       "2516539    Storm Kayamas old high school friend, Tanner W...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_books['description'].sample()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 206), dtype=int64, numpy=\n",
       "array([[  1270, 219574,    118,    330,    307,    142,   5852,   2924,\n",
       "           207,      3,   3006,    101,   1413,      9,      6,    152,\n",
       "             6,  60990,      6,    158,    466,     10,   2793,      8,\n",
       "           610,    220,    820,      5,     10,   9207,    183,      3,\n",
       "          1420,  10155,  30317,      7,      2,   8588,   6135,    425,\n",
       "           467,      4,    811,   2052,  79411,      8,    953,      2,\n",
       "          3046,     11,      3,  60990, 110065,   8023,  25124,   2361,\n",
       "             3,    396,      7,      2,    630,      5,  11222,  23015,\n",
       "             2,    183,      5,     19,  25101,  14118,   7719,     23,\n",
       "           727,    120,      3,    346,  12035,     13,   1270,      4,\n",
       "         79411,      6,    125,    224,     21,  13593,     13,      2,\n",
       "          1684,     16,   1270,    133,    103,     11,   5852,     20,\n",
       "          2960,   1232,     75,     14,    635,     15,    440,     10,\n",
       "          2098,    182,   2724,   2924,      3,    283,      5,   2380,\n",
       "          4053,      4,   1834,      6,      3,    226,  10753,    418,\n",
       "          1729,      6,     19,   1229,   5330,    556,      3,    370,\n",
       "           529,     78,   6135,   1142,      6,  11989,    112,   4603,\n",
       "          2172,   2924,    103,     10,    225,     79,     15,     33,\n",
       "           350,    585,   1935,   2172,    758,      2,     88,    113,\n",
       "            14,    830,   1270,    668,   2172,    121,     39,    503,\n",
       "            10,    986,     60,      4,      8,      7,   1027,    285,\n",
       "            21,    180,      2,    334,      4,     10, 241034,    359,\n",
       "        235994,   3309,      9,   1058,     78, 207976, 278971,    139,\n",
       "             2,  11015,  40168,   9924,   6343,      4,  19308,   7945,\n",
       "             5, 200837,  11222, 107459,    630,      4,   2724,   2924,\n",
       "            74,   1729,      6,      2,    118,    556]], dtype=int64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['into', 'will', 'they', 'him', 'have', 'e', 'life', 'all', 'out', 'its']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_text.get_vocabulary()[35:45]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To finish the processing, we now need to embed the text. Because each title contains multiple words, we will get multiple embeddings for each title. For use in a donwstream model these are usually compressed into a single embedding. Models like RNNs or Transformers are useful here, but averaging all the words' embeddings together is a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_lookup = tf.keras.layers.StringLookup()\n",
    "user_id_lookup.adapt(df_reviews[\"user_id\"])\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32)\n",
    "\n",
    "user_id_model = tf.keras.Sequential([tf.keras.Input(shape=(1,), dtype=tf.string), user_id_lookup, user_id_embedding])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "außer ID hab ich keine Infos zum User. könnte noch die Timestamps hinzufügen, ja. will ich aber erstmal nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [[[ 0.03676773  0.02399799  0.03393122 -0.02682499 -0.01497364\n",
      "    0.01548943 -0.0463771  -0.0040454   0.02141673  0.00218928\n",
      "   -0.01313556 -0.00419117 -0.01833665 -0.04250544 -0.04027412\n",
      "   -0.03447889  0.00763812  0.01837161 -0.0106344   0.03355536\n",
      "   -0.00362672 -0.02506605  0.02969397 -0.02095327  0.00200088\n",
      "   -0.03212874 -0.04628074  0.02463732  0.00325201  0.02798146\n",
      "   -0.00209218  0.00934591]]]\n",
      "Computed representations: [[[-0.01933162 -0.00532739  0.04377028  0.01310365 -0.0256615\n",
      "    0.03164845  0.02509285  0.0153225   0.01659072 -0.04679772\n",
      "   -0.0037107  -0.04951607  0.00525152  0.00392311 -0.04494044\n",
      "    0.04446206 -0.04955762 -0.01787345  0.04363413  0.02332539\n",
      "   -0.0259964  -0.01419444 -0.00015927 -0.02043463 -0.03585851\n",
      "    0.00241078  0.00375281  0.04275284 -0.03490371  0.03385906\n",
      "   -0.04698585  0.01285278]]]\n"
     ]
    }
   ],
   "source": [
    "for row in df_reviews['user_id'].sample(2):\n",
    "  print(f\"Computed representations: {user_id_model.predict([row])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, title_vocabulary, description_vocabulary, author_vocabulary):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "    embedding_dim = 32\n",
    "\n",
    "    self.title_vectorization_layer = tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "    self.title_vectorization_layer.adapt(title_vocabulary)\n",
    "    \n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorization_layer,\n",
    "      tf.keras.layers.Embedding(max_tokens, embedding_dim, name=\"embedding\"),\n",
    "      # We average the embedding of individual words to get one embedding vector\n",
    "      # per description.\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.description_text_vectorization_layer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=max_tokens)\n",
    "    self.description_text_vectorization_layer.adapt(description_vocabulary)\n",
    "    \n",
    "    self.description_text_embedding = tf.keras.Sequential([\n",
    "      self.description_text_vectorization_layer,\n",
    "      tf.keras.layers.Embedding(max_tokens, embedding_dim, name=\"embedding\"),\n",
    "      # We average the embedding of individual words to get one embedding vector\n",
    "      # per description.\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    # author IDs are numerical\n",
    "    #from sample list of author ids create a continous range\n",
    "    # train an embedding representation of this range\n",
    "    self.author_id_lookup = tf.keras.layers.IntegerLookup()\n",
    "    self.author_id_lookup.adapt(author_vocabulary)\n",
    "\n",
    "    self.author_id_embedding = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape=(1,), dtype='int64'), \n",
    "      self.author_id_lookup,\n",
    "      tf.keras.layers.Embedding(self.author_id_lookup.vocabulary_size(), embedding_dim, name=\"embedding\")\n",
    "      ])\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    #TODO\n",
    "    return tf.concat([\n",
    "        self.title_embedding(inputs[\"title\"]),\n",
    "        self.description_text_embedding(inputs[\"description\"]),\n",
    "        self.author_id_embedding(inputs[\"author_id\"]),\n",
    "    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_model = BookModel(\n",
    "    title_vocabulary = df_books['title'],\n",
    "    description_vocabulary = df_books['description'],\n",
    "    author_vocabulary=df_books['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11297506</th>\n",
       "      <td>b'Murder on the Interstate (Logan &amp; Cafferty, ...</td>\n",
       "      <td>While traveling a northern Arizona highway, Se...</td>\n",
       "      <td>2014086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "book_id                                                       \n",
       "11297506  b'Murder on the Interstate (Logan & Cafferty, ...   \n",
       "\n",
       "                                                description  author_id  \n",
       "book_id                                                                 \n",
       "11297506  While traveling a northern Arizona highway, Se...    2014086  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_books[['title', 'description', 'author_id']].sample(1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 96), dtype=float32, numpy=\n",
       "array([[ 1.36308745e-02, -1.00424782e-04,  4.92974836e-03,\n",
       "        -7.21854623e-03, -4.45580896e-04,  2.48784572e-03,\n",
       "        -6.33176969e-05, -1.01633072e-02,  2.00869725e-03,\n",
       "        -2.38350127e-02, -2.04396266e-02, -8.13369639e-03,\n",
       "        -2.53176522e-02,  9.26260836e-03, -3.75619042e-03,\n",
       "        -1.51012400e-02, -9.51328035e-03,  2.56669300e-04,\n",
       "        -2.34544463e-02, -1.81150436e-02,  4.27870173e-03,\n",
       "         1.14700885e-03,  1.35055976e-02, -3.79976630e-03,\n",
       "        -1.89826742e-03, -8.42983648e-03,  1.42757725e-02,\n",
       "         9.74639202e-04, -1.94532294e-02, -6.94482122e-03,\n",
       "        -2.23167194e-03,  1.12741655e-02,  5.38914511e-03,\n",
       "        -5.17953187e-03,  7.79309217e-03, -3.75817763e-03,\n",
       "         3.98984551e-03,  1.26012517e-02,  1.04575492e-02,\n",
       "         2.63223075e-04, -7.79145584e-03,  6.11317065e-03,\n",
       "         6.04703731e-04, -1.57060695e-03, -3.40280379e-03,\n",
       "         4.63121152e-03,  1.84182706e-03, -2.08296068e-03,\n",
       "         3.69713921e-03, -4.70684608e-03, -2.40774266e-03,\n",
       "         8.22568685e-03, -5.52309817e-03, -8.30716547e-03,\n",
       "         6.08690362e-03, -9.43112560e-03,  1.03805287e-04,\n",
       "         4.14539222e-03, -1.37740711e-03,  1.12454605e-03,\n",
       "         2.47377367e-03, -3.32338922e-03, -4.75032022e-03,\n",
       "         6.17794320e-03, -1.09109282e-02, -1.06096268e-05,\n",
       "        -4.35602665e-02, -1.39010921e-02,  8.63730907e-04,\n",
       "        -1.04098693e-02,  2.07023956e-02, -8.50675255e-03,\n",
       "         2.15794556e-02, -4.80243228e-02,  4.81855907e-02,\n",
       "         4.48651239e-03,  2.86262520e-02, -3.99434194e-02,\n",
       "        -3.80921252e-02,  2.73336805e-02,  2.85770930e-02,\n",
       "        -2.84498818e-02, -4.73921672e-02, -3.24483290e-02,\n",
       "         3.48724462e-02,  3.19812559e-02, -2.35408433e-02,\n",
       "        -1.46785490e-02, -2.73484234e-02, -4.59268093e-02,\n",
       "         3.68235819e-02,  1.43539645e-02, -4.61471193e-02,\n",
       "         3.89038213e-02, -2.71895882e-02,  4.77413796e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_model(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_ids, review_ids, book_ids):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "    embedding_dim = 32\n",
    "\n",
    "    # Book IDs are numerical\n",
    "    #from sample list of book ids create a continous range\n",
    "    # train an embedding representation of this range\n",
    "    self.book_id_lookup = tf.keras.layers.IntegerLookup()\n",
    "    self.book_id_lookup.adapt(book_ids)\n",
    "\n",
    "    self.book_id_embedding = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape=(1,), dtype='int64'), \n",
    "      self.book_id_lookup,\n",
    "      tf.keras.layers.Embedding(self.book_id_lookup.vocabulary_size(), embedding_dim, name=\"embedding\")\n",
    "      ])\n",
    "\n",
    "    # Review and User IDs are alphanumerical\n",
    "    \n",
    "    self.review_id_vectorization_layer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=max_tokens)\n",
    "    self.review_id_vectorization_layer.adapt(review_ids)\n",
    "\n",
    "    self.review_id_embedding = tf.keras.Sequential([\n",
    "      self.review_id_vectorization_layer,\n",
    "      tf.keras.layers.Embedding(self.review_id_vectorization_layer.vocabulary_size(), embedding_dim, name=\"embedding\"),\n",
    "      # We average the embedding of individual words to get one embedding vector\n",
    "      # per description.\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.user_id_vectorization_layer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=max_tokens)\n",
    "    self.user_id_vectorization_layer.adapt(user_ids)\n",
    "\n",
    "    self.user_id_embedding = tf.keras.Sequential([\n",
    "      self.user_id_vectorization_layer,\n",
    "      tf.keras.layers.Embedding(self.user_id_vectorization_layer.vocabulary_size(), embedding_dim, name=\"embedding\"),\n",
    "      #TODO MASK ZERO??\n",
    "      # We average the embedding of individual words to get one embedding vector\n",
    "      # per description.\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "\n",
    "  def call(self, inputs: pd.DataFrame):\n",
    "    #TODO\n",
    "    if 'review_id' in inputs.keys():\n",
    "      review_input = inputs['review_id']\n",
    "    elif inputs.index.name == 'review_id':\n",
    "      review_input = inputs.index\n",
    "    else:\n",
    "      raise ValueError(\"'review_id' neither index nor column\")\n",
    "    return tf.concat([\n",
    "        self.book_id_embedding(inputs[\"book_id\"]),\n",
    "        self.review_id_embedding(review_input),\n",
    "        self.user_id_embedding(inputs[\"user_id\"]),\n",
    "    ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    }
   ],
   "source": [
    "review_model = ReviewModel(\n",
    "    user_ids = df_reviews['user_id'],\n",
    "    review_ids = df_reviews.index,\n",
    "    book_ids=df_reviews['book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152c0a5b68a9271bba1716c9ac867393</th>\n",
       "      <td>659186143b55358ca7f9b26cc6aa0634</td>\n",
       "      <td>18775247</td>\n",
       "      <td>4</td>\n",
       "      <td>i'm pissed i didn't read this sooner lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           user_id   book_id  \\\n",
       "review_id                                                                      \n",
       "152c0a5b68a9271bba1716c9ac867393  659186143b55358ca7f9b26cc6aa0634  18775247   \n",
       "\n",
       "                                  rating  \\\n",
       "review_id                                  \n",
       "152c0a5b68a9271bba1716c9ac867393       4   \n",
       "\n",
       "                                                               review_text  \n",
       "review_id                                                                   \n",
       "152c0a5b68a9271bba1716c9ac867393  i'm pissed i didn't read this sooner lol  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_reviews.sample(1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 96), dtype=float32, numpy=\n",
       "array([[-0.0028586 , -0.03091831,  0.01607896,  0.04697912,  0.03025583,\n",
       "         0.01199814, -0.00444038,  0.03963006, -0.03829606, -0.03585865,\n",
       "        -0.01786268,  0.01868767,  0.02994077, -0.0010972 ,  0.03992815,\n",
       "        -0.02445447,  0.00245376,  0.04150835, -0.0403934 , -0.04680669,\n",
       "        -0.03060129,  0.02973701, -0.01777003,  0.00031988,  0.01246957,\n",
       "         0.01589235,  0.02303443, -0.02682594, -0.00256842, -0.01515793,\n",
       "        -0.00168462,  0.01027632,  0.04173422,  0.04804875, -0.01320882,\n",
       "         0.02330193, -0.02479473, -0.02070893, -0.00672935, -0.02630199,\n",
       "         0.04590357,  0.04963528,  0.0407191 ,  0.03217853, -0.02726812,\n",
       "         0.00869119,  0.01918832,  0.0481332 , -0.0193388 , -0.02571688,\n",
       "        -0.02887375,  0.04855379, -0.02993959,  0.00309888, -0.0434199 ,\n",
       "        -0.00871726,  0.04729148, -0.04802017,  0.02213817,  0.00420422,\n",
       "         0.04742939,  0.03508562,  0.00080667,  0.00336868, -0.0441296 ,\n",
       "         0.03384565, -0.02709556,  0.02359943, -0.04787217,  0.01721828,\n",
       "         0.00640516, -0.03945869,  0.02040027,  0.03136374,  0.03533166,\n",
       "         0.02090153,  0.04465652, -0.01498152, -0.02935084,  0.01169568,\n",
       "         0.02812384, -0.02969292, -0.0359535 ,  0.02546129,  0.01052412,\n",
       "        -0.0336615 , -0.04894903, -0.04406571, -0.00429312,  0.03725049,\n",
       "         0.02736394, -0.03206535,  0.04205802, -0.02770865, -0.03946448,\n",
       "         0.03410436]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Breakpoint",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17184/1665742172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Breakpoint\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: Breakpoint"
     ]
    }
   ],
   "source": [
    "assert False, \"Breakpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_books['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve trained word embeddings and save them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def save_embedding_to_disk(embedding_name: str, embedding_model: tf.keras.Model, vectorization_layer: tf.keras.layers.TextVectorization):\n",
    "    weights = embedding_model.get_layer('embedding').get_weights()[0]\n",
    "    vocab = vectorization_layer.get_vocabulary()\n",
    "    out_dir = \"./data/embeddings/\"\n",
    "    out_v = io.open(os.path.join(out_dir, f'{embedding_name}_vectors.tsv'), 'w', encoding='utf-8')\n",
    "    out_m = io.open(os.path.join(out_dir, f'{embedding_name}_metadata.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "    for index, word in enumerate(vocab):\n",
    "        if index == 0:\n",
    "            continue  # skip 0, it's padding.\n",
    "        vec = weights[index]\n",
    "        out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "        out_m.write(str(word) + \"\\n\")\n",
    "    out_v.close()\n",
    "    out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BookModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error @  title :  UnicodeDecodeError('utf-8', b'\\xc3', 0, 1, 'unexpected end of data')\n"
     ]
    }
   ],
   "source": [
    "book_model_embeddings = {\n",
    "    \"title\": (book_model.title_embedding, book_model.title_vectorization_layer),\n",
    "    \"description\": (book_model.description_text_embedding, book_model.description_text_vectorization_layer),\n",
    "    \"author_id\": (book_model.author_id_embedding, book_model.author_id_lookup)\n",
    "}\n",
    "\n",
    "for key, (embedding, vectorize) in book_model_embeddings.items():\n",
    "    try:\n",
    "        save_embedding_to_disk(key, embedding, vectorize)\n",
    "    except Exception as e:\n",
    "        print(\"error @ \", key, \": \", repr(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_model_embeddings = {\n",
    "    \"book_id\": (review_model.book_id_embedding, review_model.book_id_lookup),\n",
    "    \"review_id\": (review_model.review_id_embedding, review_model.review_id_vectorization_layer),\n",
    "    \"user_id\": (review_model.user_id_embedding, review_model.user_id_vectorization_layer)\n",
    "}\n",
    "\n",
    "for key, (embedding, vectorize) in review_model_embeddings.items():\n",
    "    try:\n",
    "        save_embedding_to_disk(key, embedding, vectorize)\n",
    "    except Exception as e:\n",
    "        print(\"error @ \", key, \": \", repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Embeddings in Embedding Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Review ID kann vermutlich weg?\n",
    "### bzw. brauch ich das ReviewModel *überhaupt*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bc9e598fcbf8a93b8170aeed7972c61fdd84b24baf2eff9e2683f5bf1d2fdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ds-project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
